{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## åœ¨è¿è¡Œæœ¬ç¬”è®°æœ¬ä¹‹å‰ï¼Œè¯·å…ˆä¸‹è½½ä»¥ä¸‹å·¥å…·ï¼š\n",
    "\n",
    "1. **æŸ¥æ‰¾å½“å‰çš„ Google Chrome ç‰ˆæœ¬**  \n",
    "   - æ‰“å¼€ Google Chromeï¼Œå¹¶åœ¨åœ°å€æ è¾“å…¥ï¼š  \n",
    "     ```\n",
    "     chrome://settings/help\n",
    "     ```\n",
    "   - å»ºè®®ä½¿ç”¨ **133** ç‰ˆæœ¬çš„ Google Chromeï¼ˆæˆ–æœ€æ–°å¯ç”¨çš„ç¨³å®šç‰ˆæœ¬ï¼‰ã€‚\n",
    "\n",
    "2. **ä¸‹è½½å¯¹åº”ç‰ˆæœ¬çš„ ChromeDriver**  \n",
    "   - å‰å¾€å®˜æ–¹çš„ Chrome æµ‹è¯•ä¸‹è½½é¡µé¢ï¼š  \n",
    "     [https://googlechromelabs.github.io/chrome-for-testing/#stable](https://googlechromelabs.github.io/chrome-for-testing/#stable)  \n",
    "   - ä¸‹è½½ä¸æ‚¨çš„ Chrome ç‰ˆæœ¬ç›¸åŒ¹é…çš„ ChromeDriverã€‚  \n",
    "   - ä¾‹å¦‚ï¼Œå¦‚æœæ‚¨çš„ Chrome ç‰ˆæœ¬æ˜¯ 133ï¼Œè¯·ä¸‹è½½ **ChromeDriver 133**ã€‚\n",
    "\n",
    "3. **æŸ¥æ‰¾å·²ä¸‹è½½çš„ ChromeDriver**  \n",
    "   - å¦‚æœæ‚¨ä½¿ç”¨ macOSï¼Œå¯åœ¨ç»ˆç«¯ (Terminal) ä¸­è¿è¡Œä»¥ä¸‹å‘½ä»¤æ¥æŸ¥æ‰¾ `chromedriver` çš„ä½ç½®ï¼š\n",
    "     ```bash\n",
    "     mdfind -name chromedriver\n",
    "     ```\n",
    "   - å¦‚æœä½¿ç”¨å…¶ä»–æ“ä½œç³»ç»Ÿï¼Œè¯·æ£€æŸ¥é»˜è®¤çš„ **ä¸‹è½½** ç›®å½•æˆ–æ‚¨ä¿å­˜è¯¥æ–‡ä»¶çš„ç›®å½•ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from scrapy.selector import Selector\n",
    "from scrapy.http import TextResponse\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### å¯åŠ¨ Chrome æµè§ˆå™¨å®ä¾‹ï¼š\n",
    "\n",
    "æ‰“å¼€ **terminal**, ä¸‹è½½ Chrome Driver (å‡çš„ Google Chrome)\n",
    "\n",
    "```bash\n",
    "brew install chromedriver\n",
    "chmod +x /opt/homebrew/bin/chromedriver\n",
    "```\n",
    "\n",
    "è¾“å…¥ä»¥ä¸‹å‘½ä»¤ï¼ˆå°† `your Chrome.exe path` æ›¿æ¢ä¸ºæ‚¨çš„ Google Chrome æµè§ˆå™¨è·¯å¾„ï¼‰ï¼š\n",
    "```bash\n",
    "<your Chrome.exe path> --remote-debugging-port=9222 --user-data-dir=\"/Users/<your home folder name>/selenium/AutomationProfile\"\n",
    "```\n",
    "\n",
    "- è¯·å°†your Chrome.exe pathæ›¿æ¢ä¸ºæ‚¨çš„Chromeæµè§ˆå™¨æ‰€åœ¨è·¯å¾„ï¼Œä¾‹å¦‚<br>`C:\\Program Files\\Google\\Chrome\\Application\\chrome.exe`\n",
    "- é…ç½® chromedriver ç›¸å…³ä¿¡æ¯ï¼Œè¯·å‚è€ƒå®˜æ–¹æ–‡æ¡£ï¼š[ChromeDriver](https://developer.chrome.com/docs/chromedriver)\n",
    "- æ¥åšä¸ªæ¯”æ–¹ï¼Œ æˆ‘çš„ *terminal command* ä¼šæ˜¯:\n",
    "\n",
    "/Applications/Google\\ Chrome.app/Contents/MacOS/Google\\ Chrome \\\n",
    "  --remote-debugging-port=9222 \\\n",
    "  --user-data-dir=\"/Users/princess/selenium/AutomationProfile\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# é…ç½®Chromeæµè§ˆå™¨\n",
    "options = Options()\n",
    "options.add_experimental_option('debuggerAddress', '127.0.0.1:9222')\n",
    "options.add_argument('--incognito')\n",
    "browser = webdriver.Chrome(options=options)\n",
    "action = ActionChains(browser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å³å°†å¼€å§‹æ£€æŸ¥å°çº¢ä¹¦ç™»å½•çŠ¶æ€...\n",
      "çˆ¬å–æ•°æ®æœ‰è´¦æˆ·å°ç¦çš„é£é™©ï¼Œå»ºè®®ä½¿ç”¨éä¸»è´¦å·ç™»å½•ã€‚\n",
      "ç™»å½•æˆåŠŸ\n",
      "æ£€æŸ¥æ—¶é—´: Thu Feb  6 18:43:21 2025\n",
      "è¯·æ ¹æ®æç¤ºè¾“å…¥ç”¨æˆ·ä¸»é¡µURLå’Œç¬”è®°çˆ¬å–æ•°é‡ã€‚\n",
      "æ£€æŸ¥ç”¨æˆ·ä¸»é¡µåŠ è½½çŠ¶æ€...\n",
      "ç”¨æˆ·ä¸»é¡µåŠ è½½æˆåŠŸ\n"
     ]
    }
   ],
   "source": [
    "user_url = \"\"\n",
    "num = 0\n",
    "\n",
    "def check_login_status(browser):\n",
    "    print(\"å³å°†å¼€å§‹æ£€æŸ¥å°çº¢ä¹¦ç™»å½•çŠ¶æ€...\")\n",
    "    print(\"çˆ¬å–æ•°æ®æœ‰è´¦æˆ·å°ç¦çš„é£é™©ï¼Œå»ºè®®ä½¿ç”¨éä¸»è´¦å·ç™»å½•ã€‚\")\n",
    "    \n",
    "    while True:\n",
    "        page_source = browser.page_source\n",
    "        if 'ç™»å½•æ¢ç´¢æ›´å¤šå†…å®¹' in page_source:\n",
    "            print('æš‚æœªç™»å½•ï¼Œè¯·æ‰‹åŠ¨ç™»å½•')\n",
    "            print('æ£€æŸ¥æ—¶é—´:', time.ctime())\n",
    "            time.sleep(10)\n",
    "        else:\n",
    "            print('ç™»å½•æˆåŠŸ')\n",
    "            print('æ£€æŸ¥æ—¶é—´:', time.ctime())\n",
    "            time.sleep(3)\n",
    "            break\n",
    "\n",
    "def check_user_page_load_status(browser):\n",
    "    \"\"\"\n",
    "    æ£€æŸ¥ç”¨æˆ·ä¸»é¡µæ˜¯å¦åŠ è½½æˆåŠŸã€‚\n",
    "    è¿™é‡Œç­‰å¾…é¡µé¢ä¸­å‡ºç°è‡³å°‘ä¸€ä¸ªå¸–å­ï¼ˆåŒ…å« \"note-item\" çš„ sectionï¼‰ã€‚\n",
    "    \"\"\"\n",
    "    print(\"æ£€æŸ¥ç”¨æˆ·ä¸»é¡µåŠ è½½çŠ¶æ€...\")\n",
    "    try:\n",
    "        wait = WebDriverWait(browser, 15)\n",
    "        wait.until(EC.presence_of_element_located((By.XPATH, '//section[contains(@class, \"note-item\")]')))\n",
    "        print(\"ç”¨æˆ·ä¸»é¡µåŠ è½½æˆåŠŸ\")\n",
    "    except Exception as e:\n",
    "        print(\"ç”¨æˆ·ä¸»é¡µåŠ è½½è¶…æ—¶æˆ–å‡ºé”™:\", e)\n",
    "\n",
    "def selenium_test():\n",
    "    \"\"\"\n",
    "    ç™»å½•çŠ¶æ€æ£€æŸ¥ã€é¡µé¢åŠ è½½æ£€æŸ¥ï¼Œå¹¶æ ¹æ®ç”¨æˆ·è¾“å…¥è·³è½¬åˆ°æŒ‡å®šçš„ç”¨æˆ·ä¸»é¡µè¿›è¡Œçˆ¬å–\n",
    "    \"\"\"\n",
    "    global user_url, num\n",
    "    # é¦–å…ˆæ‰“å¼€æ¢ç´¢é¡µä»¥è§¦å‘ç™»å½•æ£€æŸ¥\n",
    "    browser.get('https://www.xiaohongshu.com/explore')\n",
    "    check_login_status(browser)\n",
    "    \n",
    "    print(\"è¯·æ ¹æ®æç¤ºè¾“å…¥ç”¨æˆ·ä¸»é¡µURLå’Œç¬”è®°çˆ¬å–æ•°é‡ã€‚\")\n",
    "    user_url = input(\"ç”¨æˆ·ä¸»é¡µURLï¼š\").strip()\n",
    "    try:\n",
    "        num = int(input(\"ç¬”è®°çˆ¬å–æ•°é‡ï¼š\"))\n",
    "    except ValueError:\n",
    "        print(\"è¯·è¾“å…¥æœ‰æ•ˆçš„æ•´æ•°ä½œä¸ºçˆ¬å–æ•°é‡ã€‚\")\n",
    "        return\n",
    "    \n",
    "    # è·³è½¬åˆ°æŒ‡å®šç”¨æˆ·ä¸»é¡µ\n",
    "    browser.get(user_url)\n",
    "    time.sleep(3)\n",
    "    check_user_page_load_status(browser)\n",
    "\n",
    "# è°ƒç”¨ selenium_test() è¿›è¡Œåˆå§‹åŒ–ï¼ˆç¡®ä¿æ­¤å¤„ browser å·²åˆ›å»ºï¼‰\n",
    "selenium_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "çˆ¬å–è¿›åº¦:  20%|â–ˆâ–ˆ        | 1/5 [00:03<00:12,  3.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ­£åœ¨åˆ†æé¡µé¢ç»“æ„...\n",
      "æ‰¾åˆ° 21 ä¸ªå†…å®¹å…ƒç´ \n",
      "å½“å‰å·²çˆ¬å–æ€»æ•°: 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "çˆ¬å–è¿›åº¦: 21it [00:06,  3.29it/s]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ€»å…±æ”¶é›†çš„æ¡ç›®æ•°: 21\n",
      "æ”¶é›†çš„æ•°æ®æ ·æœ¬:\n",
      "URL: 676f71ba000000000b0227ac\n",
      "URL: 63158aee0000000011036e6e\n",
      "URL: 62724ac20000000001027847\n",
      "URL: 62639a4100000000010294ec\n",
      "URL: 625a9529000000002103e554\n",
      "æˆªæ–­åçš„æ€»æ¡ç›®æ•°: 5\n",
      "æ”¶é›†çš„æ•°æ®æ ·æœ¬:\n",
      "ä½œè€…: é»„å­éŸ¬, ç‚¹èµ: 1.5ä¸‡, URL: 676f71ba000000000b0227ac\n",
      "ä½œè€…: é»„å­éŸ¬, ç‚¹èµ: 5620, URL: 63158aee0000000011036e6e\n",
      "ä½œè€…: é»„å­éŸ¬, ç‚¹èµ: 1ä¸‡, URL: 62724ac20000000001027847\n",
      "ä½œè€…: é»„å­éŸ¬, ç‚¹èµ: 1ä¸‡, URL: 62639a4100000000010294ec\n",
      "ä½œè€…: é»„å­éŸ¬, ç‚¹èµ: 2.4ä¸‡, URL: 625a9529000000002103e554\n",
      "å¼€å§‹æå–é™„åŠ å­—æ®µï¼ŒåŒ…æ‹¬å¸–å­å†…å®¹ã€æ—¥æœŸå‘å¸ƒå’Œè¯„è®ºæ•°é‡...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "å·²è·å–çš„ç¬”è®°æ•°é‡...:  20%|â–ˆâ–ˆ        | 1/5 [00:05<00:22,  5.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å·²æå–é™„åŠ å­—æ®µï¼Œç¬”è®°ID: 676f71ba000000000b0227ac\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "å·²è·å–çš„ç¬”è®°æ•°é‡...:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:14<00:21,  7.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å·²æå–é™„åŠ å­—æ®µï¼Œç¬”è®°ID: 63158aee0000000011036e6e\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "å·²è·å–çš„ç¬”è®°æ•°é‡...:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:19<00:12,  6.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å·²æå–é™„åŠ å­—æ®µï¼Œç¬”è®°ID: 62724ac20000000001027847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "å·²è·å–çš„ç¬”è®°æ•°é‡...:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:26<00:06,  6.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å·²æå–é™„åŠ å­—æ®µï¼Œç¬”è®°ID: 62639a4100000000010294ec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "å·²è·å–çš„ç¬”è®°æ•°é‡...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:35<00:00,  7.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å·²æå–é™„åŠ å­—æ®µï¼Œç¬”è®°ID: 625a9529000000002103e554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "å·²è·å–çš„ç¬”è®°æ•°é‡...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:39<00:00,  7.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å¼€å§‹ä¸‹è½½ä¸»å›¾ç‰‡å’Œå¤´åƒå›¾ç‰‡...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ä¸‹è½½ä¸»å›¾ç‰‡: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  3.95it/s]\n",
      "ä¸‹è½½å¤´åƒå›¾ç‰‡: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 12.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ‰€æœ‰å›¾ç‰‡ä¸‹è½½å®Œæˆã€‚\n",
      "                         Author Name Likes    Comments  \\\n",
      "URL                                                      \n",
      "676f71ba000000000b0227ac         é»„å­éŸ¬  1.5ä¸‡  å…± 2094 æ¡è¯„è®º   \n",
      "63158aee0000000011036e6e         é»„å­éŸ¬  5620  å…± 1228 æ¡è¯„è®º   \n",
      "62724ac20000000001027847         é»„å­éŸ¬    1ä¸‡           0   \n",
      "62639a4100000000010294ec         é»„å­éŸ¬    1ä¸‡  å…± 1431 æ¡è¯„è®º   \n",
      "625a9529000000002103e554         é»„å­éŸ¬  2.4ä¸‡  å…± 3317 æ¡è¯„è®º   \n",
      "\n",
      "                                                        Post Title  \\\n",
      "URL                                                                  \n",
      "676f71ba000000000b0227ac  è°ç†¬å¤œï¼Œcall me ï¼Œæˆ‘ç”¨ç»è‰²å® ä½ ï¼å¾ˆé«˜å…´æˆä¸º@ç»è‰²JIASEE å“ç‰Œå…¨çƒä»£   \n",
      "63158aee0000000011036e6e                                    æ–°æ¬¾å³å°†é™ä¸–   \n",
      "62724ac20000000001027847                                         ğŸ¥   \n",
      "62639a4100000000010294ec                                æ‰“å·¥ğŸ‘¨ğŸ»â€ğŸ­OOTD   \n",
      "625a9529000000002103e554                               å¥½ä¹…ä¸è§ ğŸ çš„å…„å¼Ÿä»¬ï¼   \n",
      "\n",
      "                                                                    Caption  \\\n",
      "URL                                                                           \n",
      "676f71ba000000000b0227ac  è°ç†¬å¤œï¼Œcall me ï¼Œæˆ‘ç”¨ç»è‰²å® ä½ ï¼å¾ˆé«˜å…´æˆä¸º@ç»è‰²JIASEE å“ç‰Œå…¨çƒä»£è¨€äºº#é»„å­éŸ¬...   \n",
      "63158aee0000000011036e6e                                              #YKYB   \n",
      "62724ac20000000001027847                                           #çˆ±å†’é™©å¤æ—¥è®¡åˆ’   \n",
      "62639a4100000000010294ec                                                N/A   \n",
      "625a9529000000002103e554                                                N/A   \n",
      "\n",
      "                          Date Published  \\\n",
      "URL                                        \n",
      "676f71ba000000000b0227ac      2024-12-27   \n",
      "63158aee0000000011036e6e      2022-09-05   \n",
      "62724ac20000000001027847      2022-05-04   \n",
      "62639a4100000000010294ec  ç¼–è¾‘äº 2022-04-23   \n",
      "625a9529000000002103e554      2022-04-16   \n",
      "\n",
      "                                                            Images  \\\n",
      "URL                                                                  \n",
      "676f71ba000000000b0227ac  images_user/676f71ba000000000b0227ac.jpg   \n",
      "63158aee0000000011036e6e  images_user/63158aee0000000011036e6e.jpg   \n",
      "62724ac20000000001027847  images_user/62724ac20000000001027847.jpg   \n",
      "62639a4100000000010294ec  images_user/62639a4100000000010294ec.jpg   \n",
      "625a9529000000002103e554  images_user/625a9529000000002103e554.jpg   \n",
      "\n",
      "                                                      Author Avatar Stars  \\\n",
      "URL                                                                         \n",
      "676f71ba000000000b0227ac  avatars_user/676f71ba000000000b0227ac.jpg  2376   \n",
      "63158aee0000000011036e6e  avatars_user/63158aee0000000011036e6e.jpg  3628   \n",
      "62724ac20000000001027847  avatars_user/62724ac20000000001027847.jpg    1ä¸‡   \n",
      "62639a4100000000010294ec  avatars_user/62639a4100000000010294ec.jpg   761   \n",
      "625a9529000000002103e554  avatars_user/625a9529000000002103e554.jpg   937   \n",
      "\n",
      "                         Author Collect Nr Author Fans Nr Author Note Nr  \\\n",
      "URL                                                                        \n",
      "676f71ba000000000b0227ac                 0              0              0   \n",
      "63158aee0000000011036e6e                 0              0              0   \n",
      "62724ac20000000001027847                 0              0              0   \n",
      "62639a4100000000010294ec                 0              0              0   \n",
      "625a9529000000002103e554                 0              0              0   \n",
      "\n",
      "                                                                  Video URL  \\\n",
      "URL                                                                           \n",
      "676f71ba000000000b0227ac  blob:https://www.xiaohongshu.com/25053225-e9cd...   \n",
      "63158aee0000000011036e6e                                                N/A   \n",
      "62724ac20000000001027847                                                N/A   \n",
      "62639a4100000000010294ec                                                N/A   \n",
      "625a9529000000002103e554                                                N/A   \n",
      "\n",
      "                                                                   User URL  \n",
      "URL                                                                          \n",
      "676f71ba000000000b0227ac  /user/profile/5aa6061f4eacab09f53a8598/676f71b...  \n",
      "63158aee0000000011036e6e  /user/profile/5aa6061f4eacab09f53a8598/63158ae...  \n",
      "62724ac20000000001027847  /user/profile/5aa6061f4eacab09f53a8598/62724ac...  \n",
      "62639a4100000000010294ec  /user/profile/5aa6061f4eacab09f53a8598/62639a4...  \n",
      "625a9529000000002103e554  /user/profile/5aa6061f4eacab09f53a8598/625a952...  \n",
      "æ•°æ®å·²ä¿å­˜åˆ° 'scraped_xhs_user.csv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# åˆå§‹åŒ–æ•°æ®å­˜å‚¨åˆ—è¡¨\n",
    "authorName_list = []\n",
    "likeNr_list = []\n",
    "URL_list = []\n",
    "userURL_list = []\n",
    "commentNr_list = []\n",
    "post_title_list = [] \n",
    "caption_list = []  # å­˜å‚¨å¸–å­å†…å®¹\n",
    "datePublished_list = []\n",
    "images_list = []\n",
    "author_avatar_list = []  # ç”¨äºå­˜å‚¨å¤´åƒå›¾ç‰‡\n",
    "starNr_list = []\n",
    "authorCollectNr_list = []\n",
    "authorFansNr_list = []\n",
    "authorNoteNr_list = []\n",
    "video_urls = [] \n",
    "\n",
    "def parsePage(page_source):\n",
    "    \"\"\"\n",
    "    è§£æå½“å‰é¡µé¢çš„HTMLå†…å®¹ï¼Œæå–ç”¨æˆ·ç¬”è®°çš„åŸºæœ¬ä¿¡æ¯å¹¶æ›´æ–°å¯¹åº”çš„åˆ—è¡¨ã€‚\n",
    "    \n",
    "    Args:\n",
    "        page_source (str): å½“å‰é¡µé¢çš„HTMLå†…å®¹\n",
    "    \"\"\"\n",
    "    response = TextResponse(url=browser.current_url, body=page_source.encode('utf-8'), encoding='utf-8')\n",
    "    selector = Selector(response)\n",
    "\n",
    "    print(\"æ­£åœ¨åˆ†æé¡µé¢ç»“æ„...\")\n",
    "\n",
    "    content_elements = selector.xpath('//section[contains(@class, \"note-item\")]')\n",
    "    if content_elements:\n",
    "        print(f\"æ‰¾åˆ° {len(content_elements)} ä¸ªå†…å®¹å…ƒç´ \")\n",
    "\n",
    "        for element in content_elements:\n",
    "            try:\n",
    "                # æå–å¸–å­ï¼ˆç¬”è®°ï¼‰çš„ç›¸å¯¹URL\n",
    "                note_url = element.xpath('.//a[contains(@class, \"cover\")]/@href').get()\n",
    "                if note_url:\n",
    "                    note_id = note_url.split('/')[-1].split('?')[0]\n",
    "                    if note_id in URL_list:\n",
    "                        continue  # é¿å…é‡å¤çˆ¬å–\n",
    "                    URL_list.append(note_id)\n",
    "                    userURL_list.append(note_url)\n",
    "\n",
    "                    # æå–ä½œè€…åå­—ï¼ˆé€šå¸¸ä¸ç”¨æˆ·ä¸»é¡µç›¸åŒï¼‰\n",
    "                    author = element.xpath('.//div[contains(@class, \"author-wrapper\")]//span[contains(@class, \"name\")]/text()').get()\n",
    "                    authorName_list.append(author.strip() if author else \"N/A\")\n",
    "\n",
    "                    # æå–ç‚¹èµæ•°é‡\n",
    "                    likes = element.xpath('.//span[contains(@class, \"like-wrapper\")]/span[contains(@class, \"count\")]/text()').get()\n",
    "                    likeNr_list.append(likes.strip() if likes else \"0\")\n",
    "\n",
    "                    # æå–å¸–å­æ ‡é¢˜\n",
    "                    post_title = element.xpath('.//a[contains(@class, \"title\")]//span/text()').getall()\n",
    "                    post_title_cleaned = ' '.join([c.strip() for c in post_title if c.strip()])\n",
    "                    post_title_list.append(post_title_cleaned if post_title_cleaned else \"N/A\")\n",
    "\n",
    "                    # æå–å›¾ç‰‡ï¼ˆä¸»å›¾ï¼‰\n",
    "                    main_image = element.xpath('.//a[contains(@class, \"cover\")]/img/@src').get()\n",
    "                    images_list.append(main_image.strip() if main_image else \"N/A\")\n",
    "\n",
    "                    # æå–å¤´åƒå›¾ç‰‡\n",
    "                    avatar_image = element.xpath('.//a[contains(@class, \"author\")]/img/@src').get()\n",
    "                    author_avatar_list.append(avatar_image.strip() if avatar_image else \"N/A\")\n",
    "\n",
    "                    # åˆå§‹åŒ–é™„åŠ å­—æ®µçš„é»˜è®¤å€¼\n",
    "                    commentNr_list.append(\"0\")\n",
    "                    datePublished_list.append(\"N/A\")\n",
    "                    starNr_list.append(\"0\")\n",
    "                    authorCollectNr_list.append(\"0\")\n",
    "                    authorFansNr_list.append(\"0\")\n",
    "                    authorNoteNr_list.append(\"0\")\n",
    "                    video_urls.append(\"N/A\")\n",
    "                    caption_list.append(\"N/A\")\n",
    "\n",
    "                    qbar.update(1)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"å¤„ç†å…ƒç´ æ—¶å‡ºé”™: {str(e)}\")\n",
    "                continue\n",
    "\n",
    "    print(f\"å½“å‰å·²çˆ¬å–æ€»æ•°: {len(URL_list)}\")\n",
    "\n",
    "def extract_additional_fields(note_url, note_id):\n",
    "    \"\"\"\n",
    "    è®¿é—®æ¯ä¸ªç¬”è®°çš„é¡µé¢ï¼Œæå–é™„åŠ å­—æ®µï¼ŒåŒ…æ‹¬è¯„è®ºæ•°é‡ã€å‘å¸ƒæ—¶é—´ã€æ”¶è—æ•°é‡ã€ç²‰ä¸æ•°é‡ã€ç¬”è®°æ•°é‡ã€è§†é¢‘URLä»¥åŠå¸–å­å†…å®¹ï¼ˆCaptionï¼‰ã€‚\n",
    "    \n",
    "    Args:\n",
    "        note_url (str): ç¬”è®°çš„ç›¸å¯¹URL\n",
    "        note_id (str): ç¬”è®°çš„å”¯ä¸€ID\n",
    "    \"\"\"\n",
    "    try:\n",
    "        full_note_url = f'https://www.xiaohongshu.com{note_url}'\n",
    "        browser.get(full_note_url)\n",
    "        \n",
    "        # ç­‰å¾…é¡µé¢åŠ è½½ä¸­å…³é”®çš„æè¿° meta æ ‡ç­¾\n",
    "        wait = WebDriverWait(browser, 15)\n",
    "        wait.until(EC.presence_of_element_located((By.XPATH, '//*[@name=\"description\"]')))\n",
    "        \n",
    "        page_source = browser.page_source\n",
    "        response = TextResponse(url=browser.current_url, body=page_source.encode('utf-8'), encoding='utf-8')\n",
    "        selector = Selector(response)\n",
    "\n",
    "        # æå–è¯„è®ºæ•°é‡\n",
    "        comments = selector.xpath('//*[@class=\"total\"]/text()').get()\n",
    "        comments = comments.strip() if comments else \"0\"\n",
    "\n",
    "        # æå–å‘å¸ƒæ—¶é—´ï¼ˆé‡‡ç”¨å¤šç§ XPath å°è¯•ï¼‰\n",
    "        date_published = selector.xpath('//*[@class=\"date\"]/text()').get()\n",
    "        if not date_published:\n",
    "            date_published = selector.xpath('//time/@datetime').get()\n",
    "        date_published = date_published.strip() if date_published else \"N/A\"\n",
    "\n",
    "        # æå–æ”¶è—æ•°é‡\n",
    "        stars = selector.xpath('//*[@class=\"count\"]/text()').get()\n",
    "        stars = stars.strip() if stars else \"0\"\n",
    "\n",
    "        # æå–ä½œè€…æ”¶è—æ•°é‡\n",
    "        collect_nr = selector.xpath('//span[contains(@class, \"collect\") or contains(@class, \"saved\")]/text()').get()\n",
    "        collect_nr = collect_nr.strip() if collect_nr else \"0\"\n",
    "\n",
    "        # æå–ä½œè€…ç²‰ä¸æ•°é‡\n",
    "        fans_nr = selector.xpath('//span[contains(@class, \"fans\") or contains(@class, \"followers\")]/text()').get()\n",
    "        fans_nr = fans_nr.strip() if fans_nr else \"0\"\n",
    "\n",
    "        # æå–ä½œè€…ç¬”è®°æ•°é‡\n",
    "        note_nr = selector.xpath('//span[contains(@class, \"notes\") or contains(@class, \"posts\")]/text()').get()\n",
    "        note_nr = note_nr.strip() if note_nr else \"0\"\n",
    "\n",
    "        # æå–è§†é¢‘ URLï¼ˆå¦‚æœæœ‰ï¼‰\n",
    "        video_url = selector.xpath('//video/@src').get()\n",
    "        video_url = video_url.strip() if video_url else \"N/A\"\n",
    "\n",
    "        # æå–å¸–å­å†…å®¹ï¼ˆCaptionï¼‰\n",
    "        caption = selector.xpath('//*[@name=\"description\"]/@content').get()\n",
    "        caption = caption.strip() if caption else \"N/A\"\n",
    "\n",
    "        # æ›´æ–°å…¨å±€åˆ—è¡¨ä¸­çš„ç›¸åº”æ¡ç›®\n",
    "        if note_id in URL_list:\n",
    "            index = URL_list.index(note_id)\n",
    "            commentNr_list[index] = comments\n",
    "            datePublished_list[index] = date_published\n",
    "            starNr_list[index] = stars\n",
    "            authorCollectNr_list[index] = collect_nr\n",
    "            authorFansNr_list[index] = fans_nr\n",
    "            authorNoteNr_list[index] = note_nr\n",
    "            video_urls[index] = video_url\n",
    "            caption_list[index] = caption\n",
    "            print(f\"å·²æå–é™„åŠ å­—æ®µï¼Œç¬”è®°ID: {note_id}\")\n",
    "        else:\n",
    "            print(f\"ç¬”è®°ID {note_id} æœªåœ¨ URL_list ä¸­æ‰¾åˆ°ã€‚\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"æå–é™„åŠ å­—æ®µæ—¶å‡ºé”™ï¼Œç¬”è®°ID: {note_id}, é”™è¯¯: {str(e)}\")\n",
    "\n",
    "def download_image(url, save_path):\n",
    "    \"\"\"\n",
    "    ä¸‹è½½å›¾ç‰‡å¹¶ä¿å­˜åˆ°æŒ‡å®šè·¯å¾„ã€‚\n",
    "    \n",
    "    Args:\n",
    "        url (str): å›¾ç‰‡çš„ URL åœ°å€\n",
    "        save_path (str): å›¾ç‰‡ä¿å­˜çš„æœ¬åœ°è·¯å¾„\n",
    "    \n",
    "    Returns:\n",
    "        bool: ä¸‹è½½æ˜¯å¦æˆåŠŸ\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(url, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        with open(save_path, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"ä¸‹è½½å›¾ç‰‡æ—¶å‡ºé”™ï¼ŒURL: {url}, é”™è¯¯: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "def create_directories():\n",
    "    \"\"\"\n",
    "    åˆ›å»ºç”¨äºå­˜å‚¨ä¸»å›¾ç‰‡å’Œå¤´åƒå›¾ç‰‡çš„ç›®å½•ã€‚\n",
    "    \"\"\"\n",
    "    if not os.path.exists('images_user'):\n",
    "        os.makedirs('images_user')\n",
    "    if not os.path.exists('avatars_user'):\n",
    "        os.makedirs('avatars_user')\n",
    "\n",
    "# åˆ›å»ºç›®å½•ä»¥å­˜å‚¨å›¾ç‰‡\n",
    "create_directories()\n",
    "\n",
    "# å®šä¹‰è¿›åº¦æ¡ç”¨äºè·Ÿè¸ªå·²çˆ¬å–çš„ç¬”è®°æ•°é‡\n",
    "qbar = tqdm(total=num, desc=\"çˆ¬å–è¿›åº¦\")\n",
    "\n",
    "# å¼€å§‹ä¸‹æ‹‰åŠ è½½é¡µé¢ç›´è‡³è¾¾åˆ°æ‰€éœ€ç¬”è®°æ•°é‡\n",
    "while len(URL_list) < num:\n",
    "    for _ in range(3):\n",
    "        browser.execute_script(\"window.scrollBy(0, 300);\")\n",
    "        time.sleep(1)\n",
    "\n",
    "    parsePage(browser.page_source)\n",
    "\n",
    "    # æ£€æµ‹æ˜¯å¦åˆ°è¾¾é¡µé¢æœ«å°¾ï¼ˆæ ¹æ®é¡µé¢æç¤ºæ–‡æœ¬åˆ¤æ–­ï¼‰\n",
    "    if '- THE END -' in browser.page_source or 'No more content' in browser.page_source:\n",
    "        print(f\"å·²åˆ°è¾¾å†…å®¹æœ«å°¾ã€‚æ€»å…±æ”¶é›†: {len(URL_list)} æ¡\")\n",
    "        break\n",
    "\n",
    "    time.sleep(random.uniform(2, 4))\n",
    "\n",
    "print(f\"æ€»å…±æ”¶é›†çš„æ¡ç›®æ•°: {len(URL_list)}\")\n",
    "if URL_list:\n",
    "    print(\"æ”¶é›†çš„æ•°æ®æ ·æœ¬:\")\n",
    "    for i in range(min(5, len(URL_list))):\n",
    "        print(f\"URL: {URL_list[i]}\")\n",
    "\n",
    "# å¦‚æœæ”¶é›†çš„æ¡ç›®è¶…è¿‡ç”¨æˆ·æ‰€éœ€æ•°é‡ï¼Œåˆ™æˆªæ–­å„ä¸ªåˆ—è¡¨\n",
    "if len(URL_list) > num:\n",
    "    URL_list = URL_list[:num]\n",
    "    authorName_list = authorName_list[:num]\n",
    "    likeNr_list = likeNr_list[:num]\n",
    "    userURL_list = userURL_list[:num]\n",
    "    commentNr_list = commentNr_list[:num]\n",
    "    post_title_list = post_title_list[:num]\n",
    "    datePublished_list = datePublished_list[:num]\n",
    "    images_list = images_list[:num]\n",
    "    author_avatar_list = author_avatar_list[:num]\n",
    "    starNr_list = starNr_list[:num]\n",
    "    authorCollectNr_list = authorCollectNr_list[:num]\n",
    "    authorFansNr_list = authorFansNr_list[:num]\n",
    "    authorNoteNr_list = authorNoteNr_list[:num]\n",
    "    video_urls = video_urls[:num]\n",
    "    caption_list = caption_list[:num]\n",
    "\n",
    "print(f\"æˆªæ–­åçš„æ€»æ¡ç›®æ•°: {len(URL_list)}\")\n",
    "print(\"æ”¶é›†çš„æ•°æ®æ ·æœ¬:\")\n",
    "for i in range(min(5, len(URL_list))):\n",
    "    print(f\"ä½œè€…: {authorName_list[i]}, ç‚¹èµ: {likeNr_list[i]}, URL: {URL_list[i]}\")\n",
    "\n",
    "qbar.close()\n",
    "\n",
    "# æå–æ¯ä¸ªç¬”è®°çš„é™„åŠ å­—æ®µï¼ˆä¾‹å¦‚å¸–å­å†…å®¹ã€å‘å¸ƒæ—¶é—´å’Œè¯„è®ºæ•°é‡ï¼‰\n",
    "print(\"å¼€å§‹æå–é™„åŠ å­—æ®µï¼ŒåŒ…æ‹¬å¸–å­å†…å®¹ã€æ—¥æœŸå‘å¸ƒå’Œè¯„è®ºæ•°é‡...\")\n",
    "qbar = tqdm(total=len(URL_list), desc=\"å·²è·å–çš„ç¬”è®°æ•°é‡...\")\n",
    "\n",
    "for note_id, note_url in zip(URL_list, userURL_list):\n",
    "    extract_additional_fields(note_url, note_id)\n",
    "    qbar.update(1)\n",
    "    time.sleep(random.uniform(2, 4))  # ç¤¼è²Œç­‰å¾…ï¼Œé¿å…æœåŠ¡å™¨è¿‡è½½\n",
    "\n",
    "qbar.close()\n",
    "\n",
    "# ä¸‹è½½ä¸»å›¾ç‰‡å’Œå¤´åƒå›¾ç‰‡\n",
    "print(\"å¼€å§‹ä¸‹è½½ä¸»å›¾ç‰‡å’Œå¤´åƒå›¾ç‰‡...\")\n",
    "\n",
    "# ä¸‹è½½ä¸»å›¾ç‰‡\n",
    "image_download_bar = tqdm(total=len(images_list), desc=\"ä¸‹è½½ä¸»å›¾ç‰‡\")\n",
    "for idx, image_url in enumerate(images_list):\n",
    "    if image_url == \"N/A\":\n",
    "        image_download_bar.update(1)\n",
    "        continue\n",
    "    # æ„é€ å›¾ç‰‡ä¿å­˜è·¯å¾„ï¼Œä½¿ç”¨ note_id ä½œä¸ºæ–‡ä»¶å\n",
    "    image_extension = os.path.splitext(image_url)[1].split('?')[0]\n",
    "    if image_extension.lower() not in ['.jpg', '.jpeg', '.png', '.gif']:\n",
    "        image_extension = '.jpg'\n",
    "    image_filename = f\"images_user/{URL_list[idx]}{image_extension}\"\n",
    "    success = download_image(image_url, image_filename)\n",
    "    if not success:\n",
    "        image_filename = \"N/A\"\n",
    "    images_list[idx] = image_filename\n",
    "    image_download_bar.update(1)\n",
    "image_download_bar.close()\n",
    "\n",
    "# ä¸‹è½½å¤´åƒå›¾ç‰‡\n",
    "avatar_download_bar = tqdm(total=len(author_avatar_list), desc=\"ä¸‹è½½å¤´åƒå›¾ç‰‡\")\n",
    "for idx, avatar_url in enumerate(author_avatar_list):\n",
    "    if avatar_url == \"N/A\":\n",
    "        avatar_download_bar.update(1)\n",
    "        continue\n",
    "    avatar_extension = os.path.splitext(avatar_url)[1].split('?')[0]\n",
    "    if avatar_extension.lower() not in ['.jpg', '.jpeg', '.png', '.gif']:\n",
    "        avatar_extension = '.jpg'\n",
    "    avatar_filename = f\"avatars_user/{URL_list[idx]}{avatar_extension}\"\n",
    "    success = download_image(avatar_url, avatar_filename)\n",
    "    if not success:\n",
    "        avatar_filename = \"N/A\"\n",
    "    author_avatar_list[idx] = avatar_filename\n",
    "    avatar_download_bar.update(1)\n",
    "avatar_download_bar.close()\n",
    "\n",
    "print(\"æ‰€æœ‰å›¾ç‰‡ä¸‹è½½å®Œæˆã€‚\")\n",
    "\n",
    "# å°†æ•°æ®æ•´ç†ä¸ºå­—å…¸ï¼ˆåŒ…æ‹¬â€œAuthor Avatarâ€ä¸â€œCaptionâ€å­—æ®µï¼‰\n",
    "data = {\n",
    "    'Author Name': authorName_list,\n",
    "    'Likes': likeNr_list,\n",
    "    'Comments': commentNr_list,\n",
    "    'Post Title': post_title_list, \n",
    "    'Caption': caption_list,\n",
    "    'Date Published': datePublished_list,\n",
    "    'Images': images_list,          # ä¸»å›¾ç‰‡çš„æœ¬åœ°è·¯å¾„\n",
    "    'Author Avatar': author_avatar_list,  # å¤´åƒå›¾ç‰‡çš„æœ¬åœ°è·¯å¾„\n",
    "    'Stars': starNr_list,\n",
    "    'Author Collect Nr': authorCollectNr_list,\n",
    "    'Author Fans Nr': authorFansNr_list,\n",
    "    'Author Note Nr': authorNoteNr_list,\n",
    "    'Video URL': video_urls,\n",
    "    'URL': URL_list,\n",
    "    'User URL': userURL_list\n",
    "}\n",
    "\n",
    "# å°†æ•°æ®å­˜å‚¨ä¸º DataFrame å¹¶å¯¼å‡º CSV\n",
    "df = pd.DataFrame(data)\n",
    "df.set_index('URL', inplace=True)\n",
    "print(df.head())\n",
    "df.to_csv('scraped_xhs_user.csv', encoding='utf-8-sig')\n",
    "print(\"æ•°æ®å·²ä¿å­˜åˆ° 'scraped_xhs_user.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stern",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
