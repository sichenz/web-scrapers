{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## åœ¨è¿è¡Œæœ¬ç¬”è®°æœ¬ä¹‹å‰ï¼Œè¯·å…ˆä¸‹è½½ä»¥ä¸‹å·¥å…·ï¼š\n",
    "\n",
    "1. **æŸ¥æ‰¾å½“å‰çš„ Google Chrome ç‰ˆæœ¬**  \n",
    "   - æ‰“å¼€ Google Chromeï¼Œå¹¶åœ¨åœ°å€æ è¾“å…¥ï¼š  \n",
    "     ```\n",
    "     chrome://settings/help\n",
    "     ```\n",
    "   - å»ºè®®ä½¿ç”¨ **133** ç‰ˆæœ¬çš„ Google Chromeï¼ˆæˆ–æœ€æ–°å¯ç”¨çš„ç¨³å®šç‰ˆæœ¬ï¼‰ã€‚\n",
    "\n",
    "2. **ä¸‹è½½å¯¹åº”ç‰ˆæœ¬çš„ ChromeDriver**  \n",
    "   - å‰å¾€å®˜æ–¹çš„ Chrome æµ‹è¯•ä¸‹è½½é¡µé¢ï¼š  \n",
    "     [https://googlechromelabs.github.io/chrome-for-testing/#stable](https://googlechromelabs.github.io/chrome-for-testing/#stable)  \n",
    "   - ä¸‹è½½ä¸æ‚¨çš„ Chrome ç‰ˆæœ¬ç›¸åŒ¹é…çš„ ChromeDriverã€‚  \n",
    "   - ä¾‹å¦‚ï¼Œå¦‚æœæ‚¨çš„ Chrome ç‰ˆæœ¬æ˜¯ 133ï¼Œè¯·ä¸‹è½½ **ChromeDriver 133**ã€‚\n",
    "\n",
    "3. **æŸ¥æ‰¾å·²ä¸‹è½½çš„ ChromeDriver**  \n",
    "   - å¦‚æœæ‚¨ä½¿ç”¨ macOSï¼Œå¯åœ¨ç»ˆç«¯ (Terminal) ä¸­è¿è¡Œä»¥ä¸‹å‘½ä»¤æ¥æŸ¥æ‰¾ `chromedriver` çš„ä½ç½®ï¼š\n",
    "     ```bash\n",
    "     mdfind -name chromedriver\n",
    "     ```\n",
    "   - å¦‚æœä½¿ç”¨å…¶ä»–æ“ä½œç³»ç»Ÿï¼Œè¯·æ£€æŸ¥é»˜è®¤çš„ **ä¸‹è½½** ç›®å½•æˆ–æ‚¨ä¿å­˜è¯¥æ–‡ä»¶çš„ç›®å½•ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯¼å…¥å¿…è¦çš„åŒ…\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "import pymongo\n",
    "import pandas as pd\n",
    "import requests  # æ–°å¢ï¼šç”¨äºä¸‹è½½å›¾ç‰‡\n",
    "\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from datetime import datetime\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from scrapy.selector import Selector\n",
    "from scrapy.http import TextResponse\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### å¯åŠ¨ Chrome æµè§ˆå™¨å®ä¾‹ï¼š\n",
    "\n",
    "æ‰“å¼€ **terminal**, ä¸‹è½½ Chrome Driver (å‡çš„ Google Chrome)\n",
    "\n",
    "```bash\n",
    "brew install chromedriver\n",
    "chmod +x /opt/homebrew/bin/chromedriver\n",
    "```\n",
    "\n",
    "è¾“å…¥ä»¥ä¸‹å‘½ä»¤ï¼ˆå°† `your Chrome.exe path` æ›¿æ¢ä¸ºæ‚¨çš„ Google Chrome æµè§ˆå™¨è·¯å¾„ï¼‰ï¼š\n",
    "```bash\n",
    "<your Chrome.exe path> --remote-debugging-port=9222 --user-data-dir=\"/Users/<your home folder name>/selenium/AutomationProfile\"\n",
    "```\n",
    "\n",
    "- è¯·å°†your Chrome.exe pathæ›¿æ¢ä¸ºæ‚¨çš„Chromeæµè§ˆå™¨æ‰€åœ¨è·¯å¾„ï¼Œä¾‹å¦‚<br>`C:\\Program Files\\Google\\Chrome\\Application\\chrome.exe`\n",
    "- é…ç½® chromedriver ç›¸å…³ä¿¡æ¯ï¼Œè¯·å‚è€ƒå®˜æ–¹æ–‡æ¡£ï¼š[ChromeDriver](https://developer.chrome.com/docs/chromedriver)\n",
    "- æ¥åšä¸ªæ¯”æ–¹ï¼Œ æˆ‘çš„ *terminal command* ä¼šæ˜¯:\n",
    "\n",
    "/Applications/Google\\ Chrome.app/Contents/MacOS/Google\\ Chrome \\\n",
    "  --remote-debugging-port=9222 \\\n",
    "  --user-data-dir=\"/Users/princess/selenium/AutomationProfile\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# é…ç½®Chromeæµè§ˆå™¨\n",
    "options = Options()\n",
    "options.add_experimental_option('debuggerAddress', '127.0.0.1:9222')\n",
    "options.add_argument('--incognito')\n",
    "browser = webdriver.Chrome(options=options)\n",
    "action = ActionChains(browser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å³å°†å¼€å§‹æ£€æŸ¥å°çº¢ä¹¦ç™»å½•çŠ¶æ€...\n",
      "çˆ¬å–æ•°æ®æœ‰è´¦æˆ·å°ç¦çš„é£é™©ï¼Œå»ºè®®ä½¿ç”¨éä¸»è´¦å·ç™»å½•ã€‚\n",
      "æš‚æœªç™»å½•ï¼Œè¯·æ‰‹åŠ¨ç™»å½•\n",
      "æ£€æŸ¥æ—¶é—´: Wed Feb  5 01:07:38 2025\n",
      "æš‚æœªç™»å½•ï¼Œè¯·æ‰‹åŠ¨ç™»å½•\n",
      "æ£€æŸ¥æ—¶é—´: Wed Feb  5 01:07:48 2025\n",
      "æš‚æœªç™»å½•ï¼Œè¯·æ‰‹åŠ¨ç™»å½•\n",
      "æ£€æŸ¥æ—¶é—´: Wed Feb  5 01:07:58 2025\n",
      "æš‚æœªç™»å½•ï¼Œè¯·æ‰‹åŠ¨ç™»å½•\n",
      "æ£€æŸ¥æ—¶é—´: Wed Feb  5 01:08:08 2025\n",
      "æš‚æœªç™»å½•ï¼Œè¯·æ‰‹åŠ¨ç™»å½•\n",
      "æ£€æŸ¥æ—¶é—´: Wed Feb  5 01:08:18 2025\n",
      "ç™»å½•æˆåŠŸ\n",
      "æ£€æŸ¥æ—¶é—´: Wed Feb  5 01:08:28 2025\n",
      "è¯·åœ¨æ–‡æœ¬æ¡†ä¸­æ ¹æ®æç¤ºè¾“å…¥æœç´¢å…³é”®è¯å’Œç¬”è®°çˆ¬å–æ•°é‡ã€‚\n",
      "å³å°†å¼€å§‹æ£€æŸ¥ç½‘é¡µåŠ è½½çŠ¶æ€...\n",
      "å¦‚æœç½‘é¡µè¿›å…¥äººæœºéªŒè¯é¡µé¢ï¼Œè¯·å…ˆæ‰‹åŠ¨å®ŒæˆéªŒè¯ã€‚\n",
      "åŠ è½½æˆåŠŸ\n",
      "æ£€æŸ¥æ—¶é—´: Wed Feb  5 01:08:39 2025\n"
     ]
    }
   ],
   "source": [
    "key_word = \"\"\n",
    "num = 0\n",
    "\n",
    "def check_login_status(browser):\n",
    "    print(\"å³å°†å¼€å§‹æ£€æŸ¥å°çº¢ä¹¦ç™»å½•çŠ¶æ€...\")\n",
    "    print(\"çˆ¬å–æ•°æ®æœ‰è´¦æˆ·å°ç¦çš„é£é™©ï¼Œå»ºè®®ä½¿ç”¨éä¸»è´¦å·ç™»å½•ã€‚\")\n",
    "    \n",
    "    while True:\n",
    "        page_source = browser.page_source\n",
    "        if 'ç™»å½•æ¢ç´¢æ›´å¤šå†…å®¹' in page_source:\n",
    "            print('æš‚æœªç™»å½•ï¼Œè¯·æ‰‹åŠ¨ç™»å½•')\n",
    "            print('æ£€æŸ¥æ—¶é—´:', time.ctime())\n",
    "            time.sleep(10)\n",
    "        else:\n",
    "            print('ç™»å½•æˆåŠŸ')\n",
    "            print('æ£€æŸ¥æ—¶é—´:', time.ctime())\n",
    "            time.sleep(3)\n",
    "            break\n",
    "\n",
    "def check_page_load_status(browser, keyword):\n",
    "    print(\"å³å°†å¼€å§‹æ£€æŸ¥ç½‘é¡µåŠ è½½çŠ¶æ€...\")\n",
    "    print(\"å¦‚æœç½‘é¡µè¿›å…¥äººæœºéªŒè¯é¡µé¢ï¼Œè¯·å…ˆæ‰‹åŠ¨å®ŒæˆéªŒè¯ã€‚\")\n",
    "    \n",
    "    while True:\n",
    "        if keyword in browser.title:\n",
    "            print('åŠ è½½æˆåŠŸ')\n",
    "            print('æ£€æŸ¥æ—¶é—´:', time.ctime())\n",
    "            break\n",
    "        else:\n",
    "            time.sleep(2)\n",
    "\n",
    "def selenium_test():\n",
    "    \"\"\"\n",
    "    ç™»å½•çŠ¶æ€æ£€æŸ¥ï¼Œç½‘é¡µåŠ è½½æ£€æŸ¥ï¼Œæ ¹æ®ç”¨æˆ·è¾“å…¥è¿›è¡Œæœç´¢\n",
    "    \"\"\"\n",
    "    global key_word, num\n",
    "    browser.get('https://www.xiaohongshu.com/explore')\n",
    "    \n",
    "    check_login_status(browser)\n",
    "    \n",
    "    print(\"è¯·åœ¨æ–‡æœ¬æ¡†ä¸­æ ¹æ®æç¤ºè¾“å…¥æœç´¢å…³é”®è¯å’Œç¬”è®°çˆ¬å–æ•°é‡ã€‚\")\n",
    "    keyword = input(\"æœç´¢å…³é”®è¯ï¼š\")\n",
    "    try:\n",
    "        num = int(input(\"ç¬”è®°çˆ¬å–æ•°é‡ï¼š\"))\n",
    "    except ValueError:\n",
    "        print(\"è¯·è¾“å…¥æœ‰æ•ˆçš„æ•´æ•°ä½œä¸ºçˆ¬å–æ•°é‡ã€‚\")\n",
    "        return\n",
    "    \n",
    "    url = f'https://www.xiaohongshu.com/search_result?keyword={keyword}&source=web_explore_feed'\n",
    "    browser.get(url)\n",
    "    time.sleep(3)\n",
    "\n",
    "    check_page_load_status(browser, keyword)\n",
    "\n",
    "selenium_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å·²è‡ªåŠ¨æ›´æ”¹æ¨¡å¼ä¸ºå›¾æ–‡ã€‚\n",
      "è¯·é€‰æ‹©æ’åºæ–¹å¼:\n",
      "1. ç»¼åˆ\n",
      "2. æœ€æ–°\n",
      "3. æœ€çƒ­\n",
      "è¯·è¾“å…¥æœ‰æ•ˆçš„æ’åºæ–¹å¼...\n"
     ]
    }
   ],
   "source": [
    "def change_mode(browser):\n",
    "    # æ›´æ”¹æ¨¡å¼ä¸ºå›¾æ–‡\n",
    "    try:\n",
    "        mode_button = browser.find_element(By.XPATH, '//*[@id=\"search-type\"]/div/div/div[2]')\n",
    "        mode_button.click()\n",
    "        print('å·²è‡ªåŠ¨æ›´æ”¹æ¨¡å¼ä¸ºå›¾æ–‡ã€‚')\n",
    "    except Exception as e:\n",
    "        print(f\"æ›´æ”¹æ¨¡å¼å¤±è´¥: {e}\")\n",
    "\n",
    "selected_order_text = ''\n",
    "def change_sort_order(browser, action):\n",
    "    # æ›´æ”¹æ’åºæ–¹å¼\n",
    "    sort_order = {\n",
    "        'ç»¼åˆ': 1,\n",
    "        'æœ€æ–°': 2,\n",
    "        'æœ€çƒ­': 3\n",
    "    }\n",
    "    print(\"è¯·é€‰æ‹©æ’åºæ–¹å¼:\")\n",
    "    for idx, order in sort_order.items():\n",
    "        print(f'{order}. {idx}')\n",
    "    \n",
    "    try:\n",
    "        global selected_order_text\n",
    "        selected_order_text = input(\"è¯·è¾“å…¥æ’åºæ–¹å¼å¯¹åº”çš„åç§°: \").strip()\n",
    "        if selected_order_text not in sort_order:\n",
    "            print(\"è¯·è¾“å…¥æœ‰æ•ˆçš„æ’åºæ–¹å¼...\")\n",
    "            return\n",
    "        \n",
    "        selected_order_index = sort_order[selected_order_text]\n",
    "    except Exception as e:\n",
    "        print(f\"å¤„ç†æ’åºé€‰æ‹©æ—¶å‡ºé”™: {e}\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        element = browser.find_element(By.XPATH, '//*[@id=\"global\"]/div[2]/div[2]/div/div[1]/div[2]')\n",
    "        action.move_to_element(element).perform()# æ¨¡æ‹Ÿé¼ æ ‡æ‚¬åœ\n",
    "        menu = browser.find_element(By.CLASS_NAME, 'dropdown-items')\n",
    "        option = menu.find_element(By.XPATH, f'/html/body/div[4]/div/li[{selected_order_index}]')\n",
    "        option.click()# æ¨¡æ‹Ÿé¼ æ ‡ç‚¹å‡»\n",
    "\n",
    "        print('å·²é€‰æ‹©æ’åºæ–¹å¼ä¸º:',selected_order_text)\n",
    "        print('æ£€æŸ¥æ—¶é—´:',time.ctime())\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"æ›´æ”¹æ’åºæ–¹å¼å¤±è´¥: {e}\")\n",
    "\n",
    "change_mode(browser)\n",
    "change_sort_order(browser, action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1721d4e78eae4287901dd0ae4299b653",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "çˆ¬å–è¿›åº¦:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å½“å‰URL: https://www.xiaohongshu.com/search_result?keyword=nyu&source=web_explore_feed&type=51\n",
      "å·²å¯¼èˆªåˆ°æœç´¢ç»“æœé¡µé¢ã€‚\n",
      "æ‰¾åˆ°å…ƒç´ ï¼Œé€‰æ‹©å™¨: //*[contains(text(), 'å›¾æ–‡')]\n",
      "æ­£åœ¨åˆ†æé¡µé¢ç»“æ„...\n",
      "æ‰¾åˆ°å®¹å™¨ï¼Œxpath: //div[contains(@class, \"note-item\")]\n",
      "æ‰¾åˆ° 18 ä¸ªå†…å®¹å…ƒç´ \n",
      "å½“å‰å·²çˆ¬å–æ€»æ•°: 16\n",
      "æ€»å…±æ”¶é›†çš„æ¡ç›®æ•°: 16\n",
      "æ”¶é›†çš„æ•°æ®æ ·æœ¬:\n",
      "URL: 67681b79000000000b0169c4\n",
      "URL: 676cac02000000000b017d51\n",
      "URL: 67a27d1f000000002602c12d\n",
      "URL: 67a2e5d9000000002901aa32\n",
      "URL: 67a29575000000002803d8b0\n",
      "æˆªæ–­åçš„æ€»æ¡ç›®æ•°: 10\n",
      "æ”¶é›†çš„æ•°æ®æ ·æœ¬:\n",
      "ä½œè€…: AiDa, ç‚¹èµ: 15, URL: 67681b79000000000b0169c4\n",
      "ä½œè€…: momoè¦æ—©ç¡, ç‚¹èµ: 11, URL: 676cac02000000000b017d51\n",
      "ä½œè€…: this_is_kang_kang, ç‚¹èµ: 94, URL: 67a27d1f000000002602c12d\n",
      "ä½œè€…: ç‘ä¼Š, ç‚¹èµ: èµ, URL: 67a2e5d9000000002901aa32\n",
      "ä½œè€…: 1åªæ‡’èŒ¶èŒ¶, ç‚¹èµ: 6, URL: 67a29575000000002803d8b0\n",
      "å¼€å§‹æå–é™„åŠ å­—æ®µï¼ŒåŒ…æ‹¬å¸–å­å†…å®¹ã€æ—¥æœŸå‘å¸ƒå’Œè¯„è®ºæ•°é‡...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c7a04dbcdf946d1a36c486197fe85a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "å·²è·å–çš„ç¬”è®°æ•°é‡...:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å·²æå–é™„åŠ å­—æ®µï¼Œç¬”è®°ID: 67681b79000000000b0169c4\n",
      "å·²æå–é™„åŠ å­—æ®µï¼Œç¬”è®°ID: 676cac02000000000b017d51\n",
      "å·²æå–é™„åŠ å­—æ®µï¼Œç¬”è®°ID: 67a27d1f000000002602c12d\n",
      "å·²æå–é™„åŠ å­—æ®µï¼Œç¬”è®°ID: 67a2e5d9000000002901aa32\n",
      "å·²æå–é™„åŠ å­—æ®µï¼Œç¬”è®°ID: 67a29575000000002803d8b0\n",
      "å·²æå–é™„åŠ å­—æ®µï¼Œç¬”è®°ID: 6646f897000000000c01973c\n",
      "å·²æå–é™„åŠ å­—æ®µï¼Œç¬”è®°ID: 675f9bb4000000000700bf04\n",
      "å·²æå–é™„åŠ å­—æ®µï¼Œç¬”è®°ID: 673c5abe0000000007034973\n",
      "å·²æå–é™„åŠ å­—æ®µï¼Œç¬”è®°ID: 67a2354d000000002602c25f\n",
      "å·²æå–é™„åŠ å­—æ®µï¼Œç¬”è®°ID: 66f6d09b000000002c029af5\n",
      "å¼€å§‹ä¸‹è½½ä¸»å›¾ç‰‡å’Œå¤´åƒå›¾ç‰‡...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3316ebca6cc7456aa6dc15a12507c2cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ä¸‹è½½ä¸»å›¾ç‰‡:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41e5f9c6c4e74483b2d89b3bc01ec21c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ä¸‹è½½å¤´åƒå›¾ç‰‡:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ‰€æœ‰å›¾ç‰‡ä¸‹è½½å®Œæˆã€‚\n",
      "                                Author Name Likes  Comments  \\\n",
      "URL                                                           \n",
      "67681b79000000000b0169c4               AiDa    15  å…± 79 æ¡è¯„è®º   \n",
      "676cac02000000000b017d51            momoè¦æ—©ç¡    11  å…± 41 æ¡è¯„è®º   \n",
      "67a27d1f000000002602c12d  this_is_kang_kang    94   å…± 7 æ¡è¯„è®º   \n",
      "67a2e5d9000000002901aa32                 ç‘ä¼Š     èµ         0   \n",
      "67a29575000000002803d8b0              1åªæ‡’èŒ¶èŒ¶     6   å…± 2 æ¡è¯„è®º   \n",
      "\n",
      "                                 Post Title  \\\n",
      "URL                                           \n",
      "67681b79000000000b0169c4  NYUæ–°ç”Ÿäº¤æµgroupï¼è¿˜èƒ½è¿›ï¼   \n",
      "676cac02000000000b017d51  NYUæ–°ç”Ÿäº¤æµgroupï¼è¿˜èƒ½è¿›ï¼   \n",
      "67a27d1f000000002602c12d   é‚£ä¸ªè®©æˆ‘å…¥å­¦NYUç„¶åé€€å­¦çš„ç”·å­©   \n",
      "67a2e5d9000000002901aa32  nyu meal plan 8ğŸ”ªå‡º   \n",
      "67a29575000000002803d8b0           nyuæ‰¾è¯¾å‹ğŸ¥²ğŸ¥²   \n",
      "\n",
      "                                                                    Caption  \\\n",
      "URL                                                                           \n",
      "67681b79000000000b0169c4  è¿™è¾¹ç»„äº†ä¸ªgroupï¼Œé‡Œé¢éå¸¸æ´»è·ƒï¼ŒNYUçš„uuéƒ½å¯ä»¥æ¥~ . ç›®å‰ä½ç½®å¿«æ»¡äº†ï¼Œæƒ³è¿›çš„é€Ÿæ¥ ...   \n",
      "676cac02000000000b017d51  è¿™è¾¹ç»„äº†ä¸ªgroupï¼Œé‡Œé¢éå¸¸æ´»è·ƒï¼ŒNYUçš„uuéƒ½å¯ä»¥æ¥~ æ¬¢è¿è¿›æ¥è®¤è¯†æ–°æœ‹å‹ï¼Œä¸ç®¡æ˜¯å­¦æœ¯é—®...   \n",
      "67a27d1f000000002602c12d  åˆè¯†æ˜¯å°å­¦æ—¶æœŸçš„å¤–æ•™è¯¾ åæ¥åŒä¸€æ‰€åˆä¸­ èµ°å»Šä¸Šæ‰“è¿‡ç…§é¢ å†åæ¥é«˜ä¸­SATè¡¥ä¹ ç»™reconne...   \n",
      "67a2e5d9000000002901aa32  8ğŸ”ªä¸€ä¸ªswipe ä¹°å¤šæœ‰ä¼˜æƒ  grubhubçº¿ä¸Šä»£ç‚¹ ç‚¹å®Œè‡ªå– å¯ä»¥zelleå¯ä»¥zfb ...   \n",
      "67a29575000000002803d8b0  intro to psych calculus 1 Trending mental heal...   \n",
      "\n",
      "                           Date Published  \\\n",
      "URL                                         \n",
      "67681b79000000000b0169c4       2024-12-22   \n",
      "676cac02000000000b017d51       2024-12-25   \n",
      "67a27d1f000000002602c12d  ç¼–è¾‘äº æ˜¨å¤© 16:23 ç¾å›½   \n",
      "67a2e5d9000000002901aa32      æ˜¨å¤© 23:15 ç¾å›½   \n",
      "67a29575000000002803d8b0      æ˜¨å¤© 17:32 ç¾å›½   \n",
      "\n",
      "                                                       Images  \\\n",
      "URL                                                             \n",
      "67681b79000000000b0169c4  images/67681b79000000000b0169c4.jpg   \n",
      "676cac02000000000b017d51  images/676cac02000000000b017d51.jpg   \n",
      "67a27d1f000000002602c12d  images/67a27d1f000000002602c12d.jpg   \n",
      "67a2e5d9000000002901aa32  images/67a2e5d9000000002901aa32.jpg   \n",
      "67a29575000000002803d8b0  images/67a29575000000002803d8b0.jpg   \n",
      "\n",
      "                                                 Author Avatar Stars  \\\n",
      "URL                                                                    \n",
      "67681b79000000000b0169c4  avatars/67681b79000000000b0169c4.jpg     3   \n",
      "676cac02000000000b017d51  avatars/676cac02000000000b017d51.jpg     èµ   \n",
      "67a27d1f000000002602c12d  avatars/67a27d1f000000002602c12d.jpg     èµ   \n",
      "67a2e5d9000000002901aa32  avatars/67a2e5d9000000002901aa32.jpg    ç‚¹èµ   \n",
      "67a29575000000002803d8b0  avatars/67a29575000000002803d8b0.jpg     èµ   \n",
      "\n",
      "                         Author Collect Nr Author Fans Nr Author Note Nr  \\\n",
      "URL                                                                        \n",
      "67681b79000000000b0169c4                 0              0              0   \n",
      "676cac02000000000b017d51                 0              0              0   \n",
      "67a27d1f000000002602c12d                 0              0              0   \n",
      "67a2e5d9000000002901aa32                 0              0              0   \n",
      "67a29575000000002803d8b0                 0              0              0   \n",
      "\n",
      "                         Video URL  \\\n",
      "URL                                  \n",
      "67681b79000000000b0169c4       N/A   \n",
      "676cac02000000000b017d51       N/A   \n",
      "67a27d1f000000002602c12d       N/A   \n",
      "67a2e5d9000000002901aa32       N/A   \n",
      "67a29575000000002803d8b0       N/A   \n",
      "\n",
      "                                                                   User URL  \n",
      "URL                                                                          \n",
      "67681b79000000000b0169c4  /search_result/67681b79000000000b0169c4?xsec_t...  \n",
      "676cac02000000000b017d51  /search_result/676cac02000000000b017d51?xsec_t...  \n",
      "67a27d1f000000002602c12d  /search_result/67a27d1f000000002602c12d?xsec_t...  \n",
      "67a2e5d9000000002901aa32  /search_result/67a2e5d9000000002901aa32?xsec_t...  \n",
      "67a29575000000002803d8b0  /search_result/67a29575000000002803d8b0?xsec_t...  \n",
      "æ•°æ®å·²ä¿å­˜åˆ° 'scraped_xhs_data.csv'\n"
     ]
    }
   ],
   "source": [
    "# åˆå§‹åŒ–æ•°æ®å­˜å‚¨åˆ—è¡¨\n",
    "authorName_list = []\n",
    "likeNr_list = []\n",
    "URL_list = []\n",
    "userURL_list = []\n",
    "commentNr_list = []\n",
    "post_title_list = [] \n",
    "caption_list = []  # å·²åˆå§‹åŒ–ï¼Œç”¨äºå­˜å‚¨å¸–å­å†…å®¹\n",
    "datePublished_list = []\n",
    "images_list = []\n",
    "author_avatar_list = []  # å•ç‹¬åˆå§‹åŒ–ç”¨äºå­˜å‚¨å¤´åƒå›¾ç‰‡\n",
    "starNr_list = []\n",
    "authorCollectNr_list = []\n",
    "authorFansNr_list = []\n",
    "authorNoteNr_list = []\n",
    "video_urls = [] \n",
    "\n",
    "def parsePage(page_source):\n",
    "    \"\"\"\n",
    "    è§£æå½“å‰é¡µé¢çš„HTMLå†…å®¹ï¼Œæå–ç¬”è®°çš„åŸºæœ¬ä¿¡æ¯å¹¶æ›´æ–°å¯¹åº”çš„åˆ—è¡¨ã€‚\n",
    "    \n",
    "    Args:\n",
    "        page_source (str): å½“å‰é¡µé¢çš„HTMLå†…å®¹\n",
    "    \"\"\"\n",
    "    response = TextResponse(url=browser.current_url, body=page_source.encode('utf-8'), encoding='utf-8')\n",
    "    selector = Selector(response)\n",
    "\n",
    "    print(\"æ­£åœ¨åˆ†æé¡µé¢ç»“æ„...\")\n",
    "\n",
    "    containers = [\n",
    "        '//div[contains(@class, \"note-item\")]'\n",
    "    ]\n",
    "\n",
    "    for container in containers:\n",
    "        elements = selector.xpath(container)\n",
    "        if elements:\n",
    "            print(f\"æ‰¾åˆ°å®¹å™¨ï¼Œxpath: {container}\")\n",
    "\n",
    "    content_elements = selector.xpath('//section[contains(@class, \"note-item\")]')\n",
    "    if content_elements:\n",
    "        print(f\"æ‰¾åˆ° {len(content_elements)} ä¸ªå†…å®¹å…ƒç´ \")\n",
    "\n",
    "        for element in content_elements:\n",
    "            try:\n",
    "                # æå–ç”¨æˆ·URL\n",
    "                user_url = element.xpath('.//a[contains(@class, \"cover\")]/@href').get()\n",
    "                if user_url:\n",
    "                    note_id = user_url.split('/')[-1].split('?')[0]\n",
    "                    if note_id in URL_list:\n",
    "                        continue  # é¿å…é‡å¤\n",
    "                    URL_list.append(note_id)\n",
    "                    userURL_list.append(user_url)\n",
    "\n",
    "                    # æå–ä½œè€…åå­—\n",
    "                    author = element.xpath('.//div[contains(@class, \"author-wrapper\")]//span[contains(@class, \"name\")]/text()').get()\n",
    "                    authorName_list.append(author.strip() if author else \"N/A\")\n",
    "\n",
    "                    # æå–ç‚¹èµæ•°é‡\n",
    "                    likes = element.xpath('.//span[contains(@class, \"like-wrapper\")]/span[contains(@class, \"count\")]/text()').get()\n",
    "                    likeNr_list.append(likes.strip() if likes else \"0\")\n",
    "\n",
    "                    # æå–å¸–å­æ ‡é¢˜\n",
    "                    post_title = element.xpath('.//a[contains(@class, \"title\")]//span/text()').getall()\n",
    "                    post_title_cleaned = ' '.join([c.strip() for c in post_title if c.strip()])\n",
    "                    post_title_list.append(post_title_cleaned if post_title_cleaned else \"N/A\")\n",
    "\n",
    "                    # æå–å›¾ç‰‡ï¼ˆä¸»å›¾ï¼‰\n",
    "                    main_image = element.xpath('.//a[contains(@class, \"cover\")]/img/@src').get()\n",
    "                    images_list.append(main_image.strip() if main_image else \"N/A\")\n",
    "\n",
    "                    # æå–å¤´åƒå›¾ç‰‡\n",
    "                    avatar_image = element.xpath('.//a[contains(@class, \"author\")]/img/@src').get()\n",
    "                    author_avatar_list.append(avatar_image.strip() if avatar_image else \"N/A\")\n",
    "\n",
    "                    # åˆå§‹åŒ–é™„åŠ å­—æ®µçš„é»˜è®¤å€¼\n",
    "                    commentNr_list.append(\"0\")\n",
    "                    datePublished_list.append(\"N/A\")\n",
    "                    starNr_list.append(\"0\")\n",
    "                    authorCollectNr_list.append(\"0\")\n",
    "                    authorFansNr_list.append(\"0\")\n",
    "                    authorNoteNr_list.append(\"0\")\n",
    "                    video_urls.append(\"N/A\")  \n",
    "                    caption_list.append(\"N/A\")  # åˆå§‹åŒ–ä¸ºé»˜è®¤å€¼\n",
    "\n",
    "                    qbar.update(1)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"å¤„ç†å…ƒç´ æ—¶å‡ºé”™: {str(e)}\")\n",
    "                continue\n",
    "\n",
    "    print(f\"å½“å‰å·²çˆ¬å–æ€»æ•°: {len(URL_list)}\")\n",
    "\n",
    "def extract_additional_fields(note_url, note_id):\n",
    "    \"\"\"\n",
    "    è®¿é—®æ¯ä¸ªç¬”è®°çš„é¡µé¢ï¼Œæå–é™„åŠ å­—æ®µï¼ŒåŒ…æ‹¬è¯„è®ºæ•°é‡ã€å‘å¸ƒæ—¶é—´ã€æ”¶è—æ•°é‡ã€ç²‰ä¸æ•°é‡ã€ç¬”è®°æ•°é‡ã€è§†é¢‘URLä»¥åŠå¸–å­å†…å®¹ï¼ˆCaptionï¼‰ã€‚\n",
    "    \n",
    "    Args:\n",
    "        note_url (str): ç¬”è®°çš„ç›¸å¯¹URL\n",
    "        note_id (str): ç¬”è®°çš„å”¯ä¸€ID\n",
    "    \"\"\"\n",
    "    try:\n",
    "        full_note_url = f'https://www.xiaohongshu.com{note_url}'\n",
    "        browser.get(full_note_url)\n",
    "        \n",
    "        # ä½¿ç”¨æ˜¾å¼ç­‰å¾…ä»£æ›¿å›ºå®šçš„ç­‰å¾…æ—¶é—´ï¼Œç­‰å¾…æè¿°metaæ ‡ç­¾åŠ è½½å®Œæˆ\n",
    "        wait = WebDriverWait(browser, 15)\n",
    "        wait.until(EC.presence_of_element_located((By.XPATH, '//*[@name=\"description\"]')))\n",
    "        \n",
    "        # è·å–é¡µé¢æºä»£ç \n",
    "        page_source = browser.page_source\n",
    "        response = TextResponse(url=browser.current_url, body=page_source.encode('utf-8'), encoding='utf-8')\n",
    "        selector = Selector(response)\n",
    "\n",
    "        # æå–è¯„è®ºæ•°é‡\n",
    "        comments = selector.xpath('//*[@class=\"total\"]/text()').get()\n",
    "        comments = comments.strip() if comments else \"0\"\n",
    "\n",
    "        # æå–å‘å¸ƒæ—¶é—´ï¼Œä½¿ç”¨å¤šä¸ªXPathç­–ç•¥\n",
    "        date_published = selector.xpath('//*[@class=\"date\"]/text()').get()\n",
    "        if not date_published:\n",
    "            # æ›¿ä»£XPathï¼Œå¦‚æœç¬¬ä¸€ä¸ªå¤±è´¥\n",
    "            date_published = selector.xpath('//time/@datetime').get()\n",
    "        date_published = date_published.strip() if date_published else \"N/A\"\n",
    "\n",
    "        # æå–æ”¶è—æ•°é‡\n",
    "        stars = selector.xpath('//*[@class=\"count\"]/text()').get()\n",
    "        stars = stars.strip() if stars else \"0\"\n",
    "\n",
    "        # æå–ä½œè€…æ”¶è—æ•°é‡\n",
    "        collect_nr = selector.xpath('//span[contains(@class, \"collect\") or contains(@class, \"saved\")]/text()').get()\n",
    "        collect_nr = collect_nr.strip() if collect_nr else \"0\"\n",
    "\n",
    "        # æå–ä½œè€…ç²‰ä¸æ•°é‡\n",
    "        fans_nr = selector.xpath('//span[contains(@class, \"fans\") or contains(@class, \"followers\")]/text()').get()\n",
    "        fans_nr = fans_nr.strip() if fans_nr else \"0\"\n",
    "\n",
    "        # æå–ä½œè€…ç¬”è®°æ•°é‡\n",
    "        note_nr = selector.xpath('//span[contains(@class, \"notes\") or contains(@class, \"posts\")]/text()').get()\n",
    "        note_nr = note_nr.strip() if note_nr else \"0\"\n",
    "\n",
    "        # æå–è§†é¢‘URLï¼ˆå¦‚æœæœ‰ï¼‰\n",
    "        video_url = selector.xpath('//video/@src').get()\n",
    "        video_url = video_url.strip() if video_url else \"N/A\"\n",
    "\n",
    "        # æå–å¸–å­å†…å®¹ï¼ˆCaptionï¼‰\n",
    "        caption = selector.xpath('//*[@name=\"description\"]/@content').get()\n",
    "        caption = caption.strip() if caption else \"N/A\"\n",
    "\n",
    "        # æ›´æ–°å…¨å±€åˆ—è¡¨\n",
    "        if note_id in URL_list:\n",
    "            index = URL_list.index(note_id)\n",
    "            commentNr_list[index] = comments\n",
    "            datePublished_list[index] = date_published\n",
    "            starNr_list[index] = stars\n",
    "            authorCollectNr_list[index] = collect_nr\n",
    "            authorFansNr_list[index] = fans_nr\n",
    "            authorNoteNr_list[index] = note_nr\n",
    "            video_urls[index] = video_url\n",
    "            caption_list[index] = caption  # å­˜å‚¨æå–çš„å¸–å­å†…å®¹\n",
    "            print(f\"å·²æå–é™„åŠ å­—æ®µï¼Œç¬”è®°ID: {note_id}\")\n",
    "        else:\n",
    "            print(f\"ç¬”è®°ID {note_id} æœªåœ¨URL_listä¸­æ‰¾åˆ°ã€‚\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"æå–é™„åŠ å­—æ®µæ—¶å‡ºé”™ï¼Œç¬”è®°ID: {note_id}, é”™è¯¯: {str(e)}\")\n",
    "\n",
    "def ensure_search_results():\n",
    "    \"\"\"\n",
    "    ç¡®ä¿å·²å¯¼èˆªåˆ°æœç´¢ç»“æœé¡µé¢ï¼Œå¹¶é€‰æ‹©â€œå›¾æ–‡â€æ¨¡å¼ã€‚\n",
    "    \"\"\"\n",
    "    current_url = browser.current_url\n",
    "    print(f\"å½“å‰URL: {current_url}\")\n",
    "\n",
    "    search_url = f'https://www.xiaohongshu.com/search_result?keyword={key_word}&source=web_explore_feed'\n",
    "    browser.get(search_url)\n",
    "\n",
    "    try:\n",
    "        # ç­‰å¾…é¡µé¢æ ‡é¢˜åŒ…å«å…³é”®è¯\n",
    "        wait = WebDriverWait(browser, 15)\n",
    "        wait.until(EC.title_contains(key_word))\n",
    "        print(\"å·²å¯¼èˆªåˆ°æœç´¢ç»“æœé¡µé¢ã€‚\")\n",
    "    except:\n",
    "        print(\"å¯¼èˆªåˆ°æœç´¢ç»“æœé¡µé¢æ—¶è¶…æ—¶ã€‚\")\n",
    "        browser.quit()\n",
    "        exit()\n",
    "\n",
    "    try:\n",
    "        selectors = [\n",
    "            \"//div[text()='å›¾æ–‡']\",\n",
    "            \"//div[contains(@class, 'tab')]//span[text()='å›¾æ–‡']\",\n",
    "            \"//div[contains(@class, 'filter')]//div[text()='å›¾æ–‡']\",\n",
    "            \"//*[contains(text(), 'å›¾æ–‡')]\"\n",
    "        ]\n",
    "\n",
    "        for selector in selectors:\n",
    "            try:\n",
    "                element = WebDriverWait(browser, 10).until(\n",
    "                    EC.element_to_be_clickable((By.XPATH, selector))\n",
    "                )\n",
    "                print(f\"æ‰¾åˆ°å…ƒç´ ï¼Œé€‰æ‹©å™¨: {selector}\")\n",
    "                element.click()\n",
    "                time.sleep(2)  # ç­‰å¾…æ¨¡å¼åˆ‡æ¢\n",
    "                break\n",
    "            except:\n",
    "                continue\n",
    "        else:\n",
    "            print(\"æœªæ‰¾åˆ°â€œå›¾æ–‡â€æ ‡ç­¾ï¼Œå¯èƒ½é¡µé¢ç»“æ„å·²æ›´æ”¹ã€‚\")\n",
    "    except Exception as e:\n",
    "        print(f\"åˆ‡æ¢è§†å›¾æ—¶å‡ºé”™: {e}\")\n",
    "\n",
    "    # ç­‰å¾…ä»»ä½•å†…å®¹åŠ è½½å®Œæˆ\n",
    "    time.sleep(3)\n",
    "\n",
    "def download_image(url, save_path):\n",
    "    \"\"\"\n",
    "    ä¸‹è½½å›¾ç‰‡å¹¶ä¿å­˜åˆ°æŒ‡å®šè·¯å¾„ã€‚\n",
    "    \n",
    "    Args:\n",
    "        url (str): å›¾ç‰‡çš„URLåœ°å€ã€‚\n",
    "        save_path (str): å›¾ç‰‡ä¿å­˜çš„æœ¬åœ°è·¯å¾„ã€‚\n",
    "    \n",
    "    Returns:\n",
    "        bool: ä¸‹è½½æ˜¯å¦æˆåŠŸã€‚\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(url, timeout=10)\n",
    "        response.raise_for_status()  # æ£€æŸ¥è¯·æ±‚æ˜¯å¦æˆåŠŸ\n",
    "        with open(save_path, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"ä¸‹è½½å›¾ç‰‡æ—¶å‡ºé”™ï¼ŒURL: {url}, é”™è¯¯: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "# åˆ›å»ºç›®å½•ç”¨äºå­˜å‚¨å›¾ç‰‡\n",
    "def create_directories():\n",
    "    \"\"\"\n",
    "    åˆ›å»ºç”¨äºå­˜å‚¨ä¸»å›¾ç‰‡å’Œå¤´åƒå›¾ç‰‡çš„ç›®å½•ã€‚\n",
    "    \"\"\"\n",
    "    if not os.path.exists('images'):\n",
    "        os.makedirs('images')\n",
    "    if not os.path.exists('avatars'):\n",
    "        os.makedirs('avatars')\n",
    "\n",
    "# è°ƒç”¨ç›®å½•åˆ›å»ºå‡½æ•°\n",
    "create_directories()\n",
    "\n",
    "# å®šä¹‰è¿›åº¦æ¡:å®æ—¶è·Ÿè¸ªå·²çˆ¬å–çš„ç¬”è®°æ•°é‡\n",
    "qbar = tqdm(total=num, desc=\"çˆ¬å–è¿›åº¦\")\n",
    "\n",
    "ensure_search_results()\n",
    "\n",
    "while len(URL_list) < num:\n",
    "    for _ in range(3):\n",
    "        browser.execute_script(\"window.scrollBy(0, 300);\")\n",
    "        time.sleep(1)\n",
    "\n",
    "    parsePage(browser.page_source)\n",
    "\n",
    "    if '- THE END -' in browser.page_source or 'No more content' in browser.page_source:\n",
    "        print(f\"å·²åˆ°è¾¾å†…å®¹æœ«å°¾ã€‚æ€»å…±æ”¶é›†: {len(URL_list)} æ¡\")\n",
    "        break\n",
    "\n",
    "    time.sleep(random.uniform(2, 4))\n",
    "\n",
    "print(f\"æ€»å…±æ”¶é›†çš„æ¡ç›®æ•°: {len(URL_list)}\")\n",
    "if URL_list:\n",
    "    print(\"æ”¶é›†çš„æ•°æ®æ ·æœ¬:\")\n",
    "    for i in range(min(5, len(URL_list))):\n",
    "        print(f\"URL: {URL_list[i]}\")\n",
    "\n",
    "if len(URL_list) > num:\n",
    "    URL_list = URL_list[:num]\n",
    "    authorName_list = authorName_list[:num]\n",
    "    likeNr_list = likeNr_list[:num]\n",
    "    userURL_list = userURL_list[:num]\n",
    "    commentNr_list = commentNr_list[:num]\n",
    "    post_title_list = post_title_list[:num]\n",
    "    datePublished_list = datePublished_list[:num]\n",
    "    images_list = images_list[:num]\n",
    "    author_avatar_list = author_avatar_list[:num]  # æˆªæ–­å¤´åƒåˆ—è¡¨\n",
    "    starNr_list = starNr_list[:num]\n",
    "    authorCollectNr_list = authorCollectNr_list[:num]\n",
    "    authorFansNr_list = authorFansNr_list[:num]\n",
    "    authorNoteNr_list = authorNoteNr_list[:num]\n",
    "    video_urls = video_urls[:num]\n",
    "    caption_list = caption_list[:num]  # æˆªæ–­å¸–å­å†…å®¹åˆ—è¡¨\n",
    "\n",
    "print(f\"æˆªæ–­åçš„æ€»æ¡ç›®æ•°: {len(URL_list)}\")\n",
    "print(\"æ”¶é›†çš„æ•°æ®æ ·æœ¬:\")\n",
    "for i in range(min(5, len(URL_list))):\n",
    "    print(f\"ä½œè€…: {authorName_list[i]}, ç‚¹èµ: {likeNr_list[i]}, URL: {URL_list[i]}\")\n",
    "\n",
    "qbar.close()\n",
    "\n",
    "# æå–é™„åŠ å­—æ®µï¼ŒåŒ…æ‹¬å¸–å­å†…å®¹ã€æ—¥æœŸå‘å¸ƒå’Œè¯„è®ºæ•°é‡\n",
    "print(\"å¼€å§‹æå–é™„åŠ å­—æ®µï¼ŒåŒ…æ‹¬å¸–å­å†…å®¹ã€æ—¥æœŸå‘å¸ƒå’Œè¯„è®ºæ•°é‡...\")\n",
    "qbar = tqdm(total=len(URL_list), desc=\"å·²è·å–çš„ç¬”è®°æ•°é‡...\")\n",
    "\n",
    "for note_id, note_url in zip(URL_list, userURL_list):\n",
    "    extract_additional_fields(note_url, note_id)\n",
    "    qbar.update(1)\n",
    "    time.sleep(random.uniform(2, 4))  # ç¤¼è²Œç­‰å¾…ï¼Œé¿å…æœåŠ¡å™¨å‹åŠ›è¿‡å¤§\n",
    "\n",
    "qbar.close()\n",
    "\n",
    "# ä¸‹è½½å›¾ç‰‡\n",
    "print(\"å¼€å§‹ä¸‹è½½ä¸»å›¾ç‰‡å’Œå¤´åƒå›¾ç‰‡...\")\n",
    "\n",
    "# ä¸‹è½½ä¸»å›¾ç‰‡\n",
    "image_download_bar = tqdm(total=len(images_list), desc=\"ä¸‹è½½ä¸»å›¾ç‰‡\")\n",
    "for idx, image_url in enumerate(images_list):\n",
    "    if image_url == \"N/A\":\n",
    "        image_download_bar.update(1)\n",
    "        continue\n",
    "    # æ„é€ å›¾ç‰‡ä¿å­˜è·¯å¾„ï¼Œä½¿ç”¨note_idä½œä¸ºæ–‡ä»¶å\n",
    "    image_extension = os.path.splitext(image_url)[1].split('?')[0]  # è·å–æ–‡ä»¶æ‰©å±•å\n",
    "    if image_extension.lower() not in ['.jpg', '.jpeg', '.png', '.gif']:\n",
    "        image_extension = '.jpg'  # é»˜è®¤ä½¿ç”¨.jpg\n",
    "    image_filename = f\"images/{URL_list[idx]}{image_extension}\"\n",
    "    success = download_image(image_url, image_filename)\n",
    "    if not success:\n",
    "        image_filename = \"N/A\"  # å¦‚æœä¸‹è½½å¤±è´¥ï¼Œæ ‡è®°ä¸ºN/A\n",
    "    images_list[idx] = image_filename  # æ›´æ–°ä¸ºæœ¬åœ°è·¯å¾„\n",
    "    image_download_bar.update(1)\n",
    "image_download_bar.close()\n",
    "\n",
    "# ä¸‹è½½å¤´åƒå›¾ç‰‡\n",
    "avatar_download_bar = tqdm(total=len(author_avatar_list), desc=\"ä¸‹è½½å¤´åƒå›¾ç‰‡\")\n",
    "for idx, avatar_url in enumerate(author_avatar_list):\n",
    "    if avatar_url == \"N/A\":\n",
    "        avatar_download_bar.update(1)\n",
    "        continue\n",
    "    # æ„é€ å¤´åƒä¿å­˜è·¯å¾„ï¼Œä½¿ç”¨note_idä½œä¸ºæ–‡ä»¶å\n",
    "    avatar_extension = os.path.splitext(avatar_url)[1].split('?')[0]  # è·å–æ–‡ä»¶æ‰©å±•å\n",
    "    if avatar_extension.lower() not in ['.jpg', '.jpeg', '.png', '.gif']:\n",
    "        avatar_extension = '.jpg'  # é»˜è®¤ä½¿ç”¨.jpg\n",
    "    avatar_filename = f\"avatars/{URL_list[idx]}{avatar_extension}\"\n",
    "    success = download_image(avatar_url, avatar_filename)\n",
    "    if not success:\n",
    "        avatar_filename = \"N/A\"  # å¦‚æœä¸‹è½½å¤±è´¥ï¼Œæ ‡è®°ä¸ºN/A\n",
    "    author_avatar_list[idx] = avatar_filename  # æ›´æ–°ä¸ºæœ¬åœ°è·¯å¾„\n",
    "    avatar_download_bar.update(1)\n",
    "avatar_download_bar.close()\n",
    "\n",
    "print(\"æ‰€æœ‰å›¾ç‰‡ä¸‹è½½å®Œæˆã€‚\")\n",
    "\n",
    "# åˆ›å»ºæ•°æ®å­—å…¸ï¼ŒåŒ…æ‹¬â€œAuthor Avatarâ€å’Œâ€œCaptionâ€\n",
    "data = {\n",
    "    'Author Name': authorName_list,\n",
    "    'Likes': likeNr_list,\n",
    "    'Comments': commentNr_list,\n",
    "    'Post Title': post_title_list, \n",
    "    'Caption': caption_list,  # åŒ…å«å¸–å­å†…å®¹\n",
    "    'Date Published': datePublished_list,\n",
    "    'Images': images_list,  # ä»…ä¸»å›¾çš„æœ¬åœ°è·¯å¾„\n",
    "    'Author Avatar': author_avatar_list,  # å•ç‹¬çš„å¤´åƒåˆ—è¡¨çš„æœ¬åœ°è·¯å¾„\n",
    "    'Stars': starNr_list,\n",
    "    'Author Collect Nr': authorCollectNr_list,\n",
    "    'Author Fans Nr': authorFansNr_list,\n",
    "    'Author Note Nr': authorNoteNr_list,\n",
    "    'Video URL': video_urls,\n",
    "    'URL': URL_list,\n",
    "    'User URL': userURL_list\n",
    "}\n",
    "\n",
    "# åˆ›å»ºDataFrameå¹¶ä¿å­˜ä¸ºCSV\n",
    "df = pd.DataFrame(data)\n",
    "df.set_index('URL', inplace=True)\n",
    "print(df.head())\n",
    "df.to_csv('scraped_xhs_data.csv', encoding='utf-8-sig')\n",
    "print(\"æ•°æ®å·²ä¿å­˜åˆ° 'scraped_xhs_data.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stern",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
